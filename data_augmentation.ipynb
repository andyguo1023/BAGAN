{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.8 64-bit",
      "language": "python",
      "name": "python36864bit9b0b448d0bce49f7abb4e4e85b7cb750"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "data_augmentation-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bsMexYHPOZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "05ba36bd-883c-4ee1-dcf5-0e0776510394"
      },
      "source": [
        "# Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/SingleImageDataAug/BAGAN/BAGAN code\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "bagan_train_new.py\t       data_augmentation.ipynb\trw\n",
            "bagan_train.py\t\t       Figures\t\t\tselected_index_40.npz\n",
            "balancing_gan.py\t       LICENSE\t\t\tutils.py\n",
            "batch_generator_from_input.py  README.md\n",
            "batch_generator.py\t       run.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSSq1fOs-Meh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e427cf8e-61dc-4149-88a1-9c818b5f9385"
      },
      "source": [
        "! pip install cifar10_web"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cifar10_web\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/19/4eb070a0ef1fb5f62cd9960b1b96e1d42070eea230da27d1885934e3fd46/cifar10_web-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: cifar10-web\n",
            "Successfully installed cifar10-web-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPoPE2an9EjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/SingleImageDataAug/BAGAN/BAGAN code/.\" . -a"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkiiwCOPd4n1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7968f863-b19d-4186-b0dd-733e36f79bc3"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YgGJG0A9ADl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d48b1e28-c4ac-4ecc-cc91-079d62550a49"
      },
      "source": [
        "from bagan_train_new import *"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KY3lgoG7lEp",
        "colab_type": "text"
      },
      "source": [
        "# Generating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jacCdRNX7lE_",
        "colab_type": "text"
      },
      "source": [
        "# Read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AohZy41-7lE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cifar10_web import cifar10\n",
        "import numpy as np\n",
        "\n",
        "def get_indexes(index_list, label: int = 5, drop_ratio: float = 0.4):\n",
        "\n",
        "    drop_ratio_list = dict(zip([0.4, 0.6, 0.75, 0.9],range(4)))\n",
        "    \n",
        "    return index_list[label+10*drop_ratio_list[drop_ratio]]\n",
        "\n",
        "def get_cifar_10(return_one_hot_y: bool = False):\n",
        "    \n",
        "    X_train, y_train, X_test, y_test = cifar10(path=None)\n",
        "    \n",
        "    X_train = X_train.reshape(-1,3,32,32).transpose(0,2,3,1)\n",
        "    X_test = X_test.reshape(-1,3,32,32).transpose(0,2,3,1)\n",
        "        \n",
        "    if return_one_hot_y == False:\n",
        "        y_train = np.array([np.argmax(a, axis=0) for a in y_train])\n",
        "        y_test = np.array([np.argmax(a, axis=0) for a in y_test])\n",
        "        \n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def get_imbalanced_dataset(X_train, y_train, label, drop_ratio):\n",
        "    \n",
        "    if isinstance(label,int) and isinstance(drop_ratio, float):\n",
        "        label = [label]\n",
        "        drop_ratio = [drop_ratio]\n",
        "    else:\n",
        "        label = list(label)\n",
        "        drop_ratio = list(drop_ratio)\n",
        "        \n",
        "    assert(len(label) == len(drop_ratio))\n",
        "    assert(sum([1 if i in [0.4, 0.6, 0.75, 0.9] else 0 for i in drop_ratio]) == len(drop_ratio))\n",
        "    \n",
        "    npzfile = np.load(\"selected_index_40.npz\", allow_pickle = True)\n",
        "    indexes = npzfile[\"arr_0\"]\n",
        "    \n",
        "    if y_train.ndim == 2:\n",
        "        y_train_ = np.array([np.argmax(a, axis=0) for a in y_train])\n",
        "    else:\n",
        "        y_train_ = y_train\n",
        "\n",
        "    for label_, drop_ratio_, i in zip(label, drop_ratio, range(len(label))):\n",
        "        \n",
        "        if i == 0:\n",
        "            label_index = np.where(y_train_ == label_)[0]\n",
        "            sample_index = get_indexes(indexes, label = label_, drop_ratio = drop_ratio_)\n",
        "            deleted_index = np.delete(label_index, sample_index)\n",
        "        else:\n",
        "            label_index = np.where(y_train_ == label_)[0]\n",
        "            sample_index = get_indexes(indexes, label = label_, drop_ratio = drop_ratio_)\n",
        "            print(deleted_index.shape)\n",
        "            print(np.delete(label_index, sample_index).shape)\n",
        "            deleted_index = np.concatenate((deleted_index, np.delete(label_index, sample_index)))\n",
        "    \n",
        "        \n",
        "    X_imbalanced = np.delete(X_train, deleted_index, 0)\n",
        "    y_imbalanced = np.delete(y_train, deleted_index, 0)\n",
        "\n",
        "    X_deleted = X_train[deleted_index]\n",
        "    y_deleted = y_train[deleted_index]\n",
        "\n",
        "    return X_imbalanced, y_imbalanced, X_deleted, y_deleted"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMz7Yw0D7lFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82cfcaeb-1ed1-46ac-b93c-804676baed9f"
      },
      "source": [
        "X_train, y_train, X_test, y_test = get_cifar_10()\n",
        "unbalance = [0.4]\n",
        "target_classes = [2]\n",
        "X_train_imbalanced ,y_train_imbalanced, X_deleted, y_deleted= get_imbalanced_dataset(X_train, y_train, label = target_classes, drop_ratio= unbalance)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded cifar-10-binary.tar.gz to /root/data/cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWXUp0k7lFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3ecc401-d0ed-4943-cc36-205161b84419"
      },
      "source": [
        "train_model(X_train_imbalanced ,y_train_imbalanced, X_test, y_test, unbalance = unbalance, target_classes = target_classes, output_dir = '/content/drive/My Drive/SingleImageDataAug/BAGAN', epochs=100, dataset_name='CIFAR10')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing BAGAN.\n",
            "Using dataset:  CIFAR10\n",
            "read input data...\n",
            "input data loaded...\n",
            "Required GAN for class [2]\n",
            "Class counters:  [5000, 5000, 3000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "uratio set to: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "dratio set to: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "gratio set to: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "BAGAN init_autoenc\n",
            "BAGAN: training autoencoder\n",
            "Autoencoder train epoch: 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Autoencoder train epoch: 2/100\n",
            "Autoencoder train epoch: 3/100\n",
            "Autoencoder train epoch: 4/100\n",
            "Autoencoder train epoch: 5/100\n",
            "Autoencoder train epoch: 6/100\n",
            "Autoencoder train epoch: 7/100\n",
            "Autoencoder train epoch: 8/100\n",
            "Autoencoder train epoch: 9/100\n",
            "Autoencoder train epoch: 10/100\n",
            "Autoencoder train epoch: 11/100\n",
            "Autoencoder train epoch: 12/100\n",
            "Autoencoder train epoch: 13/100\n",
            "Autoencoder train epoch: 14/100\n",
            "Autoencoder train epoch: 15/100\n",
            "Autoencoder train epoch: 16/100\n",
            "Autoencoder train epoch: 17/100\n",
            "Autoencoder train epoch: 18/100\n",
            "Autoencoder train epoch: 19/100\n",
            "Autoencoder train epoch: 20/100\n",
            "Autoencoder train epoch: 21/100\n",
            "Autoencoder train epoch: 22/100\n",
            "Autoencoder train epoch: 23/100\n",
            "Autoencoder train epoch: 24/100\n",
            "Autoencoder train epoch: 25/100\n",
            "Autoencoder train epoch: 26/100\n",
            "Autoencoder train epoch: 27/100\n",
            "Autoencoder train epoch: 28/100\n",
            "Autoencoder train epoch: 29/100\n",
            "Autoencoder train epoch: 30/100\n",
            "Autoencoder train epoch: 31/100\n",
            "Autoencoder train epoch: 32/100\n",
            "Autoencoder train epoch: 33/100\n",
            "Autoencoder train epoch: 34/100\n",
            "Autoencoder train epoch: 35/100\n",
            "Autoencoder train epoch: 36/100\n",
            "Autoencoder train epoch: 37/100\n",
            "Autoencoder train epoch: 38/100\n",
            "Autoencoder train epoch: 39/100\n",
            "Autoencoder train epoch: 40/100\n",
            "Autoencoder train epoch: 41/100\n",
            "Autoencoder train epoch: 42/100\n",
            "Autoencoder train epoch: 43/100\n",
            "Autoencoder train epoch: 44/100\n",
            "Autoencoder train epoch: 45/100\n",
            "Autoencoder train epoch: 46/100\n",
            "Autoencoder train epoch: 47/100\n",
            "Autoencoder train epoch: 48/100\n",
            "Autoencoder train epoch: 49/100\n",
            "Autoencoder train epoch: 50/100\n",
            "Autoencoder train epoch: 51/100\n",
            "Autoencoder train epoch: 52/100\n",
            "Autoencoder train epoch: 53/100\n",
            "Autoencoder train epoch: 54/100\n",
            "Autoencoder train epoch: 55/100\n",
            "Autoencoder train epoch: 56/100\n",
            "Autoencoder train epoch: 57/100\n",
            "Autoencoder train epoch: 58/100\n",
            "Autoencoder train epoch: 59/100\n",
            "Autoencoder train epoch: 60/100\n",
            "Autoencoder train epoch: 61/100\n",
            "Autoencoder train epoch: 62/100\n",
            "Autoencoder train epoch: 63/100\n",
            "Autoencoder train epoch: 64/100\n",
            "Autoencoder train epoch: 65/100\n",
            "Autoencoder train epoch: 66/100\n",
            "Autoencoder train epoch: 67/100\n",
            "Autoencoder train epoch: 68/100\n",
            "Autoencoder train epoch: 69/100\n",
            "Autoencoder train epoch: 70/100\n",
            "Autoencoder train epoch: 71/100\n",
            "Autoencoder train epoch: 72/100\n",
            "Autoencoder train epoch: 73/100\n",
            "Autoencoder train epoch: 74/100\n",
            "Autoencoder train epoch: 75/100\n",
            "Autoencoder train epoch: 76/100\n",
            "Autoencoder train epoch: 77/100\n",
            "Autoencoder train epoch: 78/100\n",
            "Autoencoder train epoch: 79/100\n",
            "Autoencoder train epoch: 80/100\n",
            "Autoencoder train epoch: 81/100\n",
            "Autoencoder train epoch: 82/100\n",
            "Autoencoder train epoch: 83/100\n",
            "Autoencoder train epoch: 84/100\n",
            "Autoencoder train epoch: 85/100\n",
            "Autoencoder train epoch: 86/100\n",
            "Autoencoder train epoch: 87/100\n",
            "Autoencoder train epoch: 88/100\n",
            "Autoencoder train epoch: 89/100\n",
            "Autoencoder train epoch: 90/100\n",
            "Autoencoder train epoch: 91/100\n",
            "Autoencoder train epoch: 92/100\n",
            "Autoencoder train epoch: 93/100\n",
            "Autoencoder train epoch: 94/100\n",
            "Autoencoder train epoch: 95/100\n",
            "Autoencoder train epoch: 96/100\n",
            "Autoencoder train epoch: 97/100\n",
            "Autoencoder train epoch: 98/100\n",
            "Autoencoder train epoch: 99/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p08-ILuO7lFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}